# 一、获取数据

上次写了篇爬取假吃强视频评论并进行数据可视化处理的博客,有小伙伴质疑真实性,那么此次本人将对假吃强所有视频的标题和描述进行可视化处理

![](https://cdn.hurra.ltd/img/20200729132457.png)

接口信息:获取 UP 主所有视频信息  
参数:

- mid : UP 主的编号
- pn : page number 页码
- ps : 每页显示的条数

此处为爬取假吃强所有视频信息的接口 URL 为:
`https://api.bilibili.com/x/space/arc/search?mid=246534959&pn=1&ps=100`  
即爬取第一页视频的信息,共 100 条.使用 Postman 测试:

![](https://cdn.hurra.ltd/img/20200729133312.png)

可以看见是没有问题的.接下来将所有视频信息爬取下来存入 JSON 文件中

```py
def get_json(mid, pn, ps):
    url = 'https://api.bilibili.com/x/space/arc/search?mid=%s&pn=%s&ps=%s' % (mid,pn, ps)
    res = requests.get(url, 'utf-8')
    # 将获取的数据转换为dict格式
    data = res.json()
    file_name = '%s-%s.json' % (mid, pn)
    # JSON文件格式为uttf-8
    with open('json/' + file_name, "w", encoding='utf-8') as fp:
        # 以JSON格式保存文件,indent决定JSON缩进,ensure_ascii确保汉字不被转换为编码
        fp.write(json.dumps(data, indent=4, ensure_ascii=False))
    print(pn + "爬取完成")

```

![](https://cdn.hurra.ltd/img/20200729133823.png)

# 二、数据分析

接下来提取每个 JSON 文件的数据,将假吃强每个视频的标题和简介分别写入两个 txt 文件中

```py
def filter_data(mid, pn):
    # 读取json文件内容,返回字典格式
    with open('json/%s-%s.json' % (mid, pn), 'r', encoding='utf8') as fp:
        data = json.load(fp)
        data = data["data"]["list"]["vlist"]
    fp.close()

    with open('title.txt', 'a', encoding='utf-8') as f1, open('description.txt', 'a', encoding='utf-8') as f2:
        for i in data:
            title = i["title"].replace('\n', '').replace('\r', '')
            description = i["description"].replace('\n', '').replace('\r', '')
            # 写入标题
            f1.write(title + '\n')
            # 过滤掉无效数据
            if description == '-' or description == '':
                continue
            # 写入简介
            f2.write(description + '\n')
    f1.close()
    f2.close()
```

![](https://cdn.hurra.ltd/img/20200729135506.png)

![](https://cdn.hurra.ltd/img/20200729135542.png)

好的,现在开始关键字分析

## 字云图

```py
def analyze_txt(file):
    # 统计字出现次数的字典
    num = {}
    # 非统计范围
    with open(file, 'r', encoding='UTF-8') as text:
        for line in text:
            for i in line:
                # 如果是汉字
                if u'\u4e00' <= i <= u'\u9fa5':
                    # 如果该字已经被统计
                    if i in num.keys():
                        num[i] += 1
                    else:
                        num[i] = 1
    wc = wordcloud.WordCloud(
        font_path='simsun.ttc',
        max_words=1000,
        max_font_size=2000,
        # 设置了背景,宽高,
        width=1000,
        height=880,
        background_color="white"
    )
    wc.generate_from_frequencies(num)
    wc.to_file("%s-word.jpg" % (file))
```

- 标题

![](https://cdn.hurra.ltd/img/20200729141350.png)

孝子们还洗吗?不是大胃王吃饭是按斤算的吗?按斤算吃的才过瘾.右下角真实

---

- 简介

![](https://cdn.hurra.ltd/img/20200729141619.png)

按一天一顿算,吃一年胃不炸,那只能是垃圾桶炸了

小伙......算了算了

## 词云图

- 标题

![](https://cdn.hurra.ltd/img/20200729141714.png)

小伙一顿不是一斤就是二斤要不三斤,再来鸡腿排骨狂吸才过瘾

- 简介

![](https://cdn.hurra.ltd/img/20200729141925.png)

假吃强今天咋不更新了

说本人锤人的,本人可以把数据发给你,所有数据均来自 B 站假吃强的主页

![](https://cdn.hurra.ltd/img/收款码.png)
